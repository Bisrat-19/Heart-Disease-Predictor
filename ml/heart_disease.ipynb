{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c84325",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction\n",
    "\n",
    "This notebook demonstrates how to build a machine learning pipeline to predict heart disease. We will use the UCI Heart Disease dataset, clean it, train two different models (Logistic Regression and Decision Tree), and evaluate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f9fcf",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "First, we load the dataset using the Pandas library. We expect the file `heart_disease_uci.csv` to be in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02eb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83c14a",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "Real-world data is often messy. In this step, we:\n",
    "1. **Drop irrelevant columns**: Identifiers like `id` and `dataset` origin don't help prediction.\n",
    "2. **Rename columns**: Ensuring consistent naming (e.g., `thalch` to `thalach`).\n",
    "3. **Encode categorical variables**: Machine learning models require numbers. We map text values (e.g., 'Male', 'Female') to numbers (1, 0).\n",
    "4. **Handle missing values**: We fill missing text data with the mode (most frequent) and numeric data with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# Step 1: Drop irrelevant columns if they exist\n",
    "irrelevant_cols = ['id', 'dataset']\n",
    "df.drop(columns=[col for col in irrelevant_cols if col in df.columns], inplace=True, errors='ignore')\n",
    "\n",
    "# Step 2: Rename columns for consistency\n",
    "df.rename(columns={'thalch': 'thalach'}, inplace=True)\n",
    "\n",
    "# Step 3: Robust Categorical Encoding\n",
    "# Using a dictionary for mapping to ensure clarity and easy updates\n",
    "mappings = {\n",
    "    'sex': {'Male': 1, 'Female': 0},\n",
    "    'cp': {'typical angina': 0, 'atypical angina': 1, 'non-anginal': 2, 'asymptomatic': 3},\n",
    "    'fbs': {True: 1, False: 0},\n",
    "    'restecg': {'normal': 0, 'st-t abnormality': 1, 'lv hypertrophy': 2},\n",
    "    'exang': {True: 1, False: 0},\n",
    "    'slope': {'upsloping': 0, 'flat': 1, 'downsloping': 2},\n",
    "    'thal': {'normal': 1, 'fixed defect': 2, 'reversable defect': 3}\n",
    "}\n",
    "\n",
    "for col, mapping in mappings.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(mapping)\n",
    "\n",
    "# Step 4: Handle Missing Values\n",
    "# Separate numeric and categorical columns for appropriate imputation\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Fill numeric NaNs with median\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Fill categorical NaNs with mode (if any left)\n",
    "for col in categorical_cols:\n",
    "    if not df[col].mode().empty:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Step 5: Target encoding (Idempotent)\n",
    "# Convert 'num' (0-4) to binary target (0=Healthy, 1=Disease)\n",
    "if 'num' in df.columns:\n",
    "    df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df.drop('num', axis=1, inplace=True)\n",
    "elif 'target' not in df.columns:\n",
    "    # Ensure target exists if num was already dropped but target somehow didn't get created\n",
    "    # This is a safety fallback\n",
    "    print(\"Warning: 'num' column not found and 'target' does not exist.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0daf39",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "We split the data into two sets:\n",
    "- **Training Set (80%)**: Used to teach the model.\n",
    "- **Test Set (20%)**: Used to evaluate how well the model generalizes to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f076f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa470a34",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling\n",
    "\n",
    "Logistic Regression performs better when all features are on a similar scale (e.g., age is 0-100, while cholesterol is 100-500). We use `StandardScaler` to normalize these features. Decision Trees generally don't require scaling, but it doesn't hurt them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25928cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7920a",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "We train two models:\n",
    "1. **Logistic Regression**: A statistical model that uses a logistic function to model a binary dependent variable.\n",
    "2. **Decision Tree**: A flowchart-like structure where an internal node represents a feature, the branch represents a decision rule, and each leaf node represents the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Train Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901141af",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "\n",
    "We evaluate the models using accuracy (percentage of correct predictions) and a classification report (Precision, Recall, F1-Score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "print(\"--- Logistic Regression Evaluation ---\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"--- Decision Tree Evaluation ---\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8b45f",
   "metadata": {},
   "source": [
    "## 7. Export Models\n",
    "\n",
    "Finally, we save the trained models and the scaler using `joblib`. These `.pkl` files will be loaded by our FastAPI backend to make real-time predictions in the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lr_model, 'logistic_model.pkl')\n",
    "joblib.dump(dt_model, 'decision_tree_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Models saved successfully: logistic_model.pkl, decision_tree_model.pkl, scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
